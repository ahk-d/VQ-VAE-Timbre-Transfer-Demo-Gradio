{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nL589kr4K9i8"
      },
      "source": [
        "# Timbre transfer demo\n",
        "\n",
        "Copyright 2020 InterDigital R&D and Télécom Paris.  \n",
        "Original Author: Ondřej Cífka\n",
        "Updates: Ali Dulaimi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-_FsWhVNMeH"
      },
      "source": [
        "## Install packages"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Local Setup Instructions\n",
        "\n",
        "**For Google Colab**: Simply run all cells in order.\n",
        "\n",
        "**For Local Environment**:\n",
        "1. Install requirements\n",
        "2. The pip uninstall/install steps are needed because:\n",
        "   - The model requires specific PyTorch versions for compatibility\n",
        "   - NumPy version conflicts can occur with DDSP dependencies\n",
        "   - These steps ensure clean installation of compatible versions\n",
        "\n",
        "**Important**: After running the NumPy downgrade cell, restart your kernel/runtime before proceeding."
      ],
      "metadata": {
        "id": "vrwVND3eoLGg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaY5aWDDC7al",
        "outputId": "0ba5a8c4-761f-47c5-e8a7-3f42e9dde8df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ss-vq-vae'...\n",
            "remote: Enumerating objects: 432, done.\u001b[K\n",
            "remote: Counting objects: 100% (69/69), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 432 (delta 58), reused 54 (delta 54), pack-reused 363 (from 1)\u001b[K\n",
            "Receiving objects: 100% (432/432), 17.87 MiB | 7.34 MiB/s, done.\n",
            "Resolving deltas: 100% (198/198), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/cifkao/ss-vq-vae.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YP868eFmNfLi"
      },
      "outputs": [],
      "source": [
        "!pip uninstall torch torchvision torchaudio accelerate -y -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbnP2LiQSS2j",
        "outputId": "10e9b2f4-a1c0-4027-bf06-43034af62967"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.4/887.4 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ss-vq-vae (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.7.19 requires torchvision>=0.11, which is not installed.\n",
            "peft 0.16.0 requires accelerate>=0.21.0, which is not installed.\n",
            "timm 1.0.16 requires torchvision, which is not installed.\n",
            "torchdata 0.11.0 requires torch>=2, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install ./ss-vq-vae/src 'numba>0.57' -q"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "⚠️ **Important**: After restarting the runtime, **DO NOT re-run the installation cells above**. Running them again may cause dependency conflicts and put you in an installation loop. Continue from the \"Load the model\" section.\n"
      ],
      "metadata": {
        "id": "DSSc9Da9qJMA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "id": "ztHhX9kq0GUu",
        "outputId": "f9a80830-da64-4f15-f62c-957855b6772a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 2.0.2\n",
            "Uninstalling numpy-2.0.2:\n",
            "  Would remove:\n",
            "    /usr/local/bin/f2py\n",
            "    /usr/local/bin/numpy-config\n",
            "    /usr/local/lib/python3.11/dist-packages/numpy-2.0.2.dist-info/*\n",
            "    /usr/local/lib/python3.11/dist-packages/numpy.libs/libgfortran-040039e1-0352e75f.so.5.0.0\n",
            "    /usr/local/lib/python3.11/dist-packages/numpy.libs/libquadmath-96973f99-934c22de.so.0.0.0\n",
            "    /usr/local/lib/python3.11/dist-packages/numpy.libs/libscipy_openblas64_-99b71e71.so\n",
            "    /usr/local/lib/python3.11/dist-packages/numpy/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled numpy-2.0.2\n",
            "Collecting numpy<2.0\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m96.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "peft 0.16.0 requires accelerate>=0.21.0, which is not installed.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "be314ce75073445ca3f722089690e586"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip uninstall numpy\n",
        "!pip install \"numpy<2.0\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference with a pre-trained model\n",
        "\n",
        "### Model Architecture Overview\n",
        "\n",
        "This VQ-VAE (Vector Quantized Variational AutoEncoder) model performs timbre transfer through three main components:\n",
        "\n",
        "### Key Components:\n",
        "- **Content Encoder**: Extracts musical content (notes, rhythm) from the input audio while discarding timbre information\n",
        "- **Style Encoder (RNN)**: Captures the timbral characteristics and playing style from the style audio using recurrent neural networks\n",
        "- **Decoder Modules**: Reconstructs audio by combining the content representation with the style features, generating output with the target timbre\n",
        "\n",
        "### Why Some Combinations Work Better:\n",
        "- **Harmonic similarity**: Instruments with similar harmonic structures transfer more effectively\n",
        "- **Spectral compatibility**: Instruments with overlapping frequency ranges produce cleaner results\n",
        "- **Temporal characteristics**: Instruments with similar attack/decay patterns maintain better musical expression"
      ],
      "metadata": {
        "id": "rQQIAClspcz-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQtNAd1hNG6R"
      },
      "source": [
        "## Download the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wy5E_vcBdXDV"
      },
      "source": [
        "#### Make sure to restart the session to load the correct NumPy version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZMig9ftDDb0o"
      },
      "outputs": [],
      "source": [
        "logdir = 'ss-vq-vae/experiments/model'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9FSW1ty4SlA",
        "outputId": "051bf11a-cc8a-4fc1-c38d-a296a0f744df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-13 15:54:54--  https://adasp.telecom-paris.fr/rc-ext/demos_companion-pages/vqvae_examples/ssvqvae_model_state.pt\n",
            "Resolving adasp.telecom-paris.fr (adasp.telecom-paris.fr)... 137.194.22.227, 2a04:8ec0:0:a::89c2:16e3\n",
            "Connecting to adasp.telecom-paris.fr (adasp.telecom-paris.fr)|137.194.22.227|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 222788899 (212M)\n",
            "Saving to: ‘ss-vq-vae/experiments/model/model_state.pt’\n",
            "\n",
            "ss-vq-vae/experimen 100%[===================>] 212.47M  14.3MB/s    in 16s     \n",
            "\n",
            "2025-07-13 15:55:10 (13.6 MB/s) - ‘ss-vq-vae/experiments/model/model_state.pt’ saved [222788899/222788899]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://adasp.telecom-paris.fr/rc-ext/demos_companion-pages/vqvae_examples/ssvqvae_model_state.pt -O $logdir/model_state.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lTeCHImQ0bhS",
        "outputId": "53322994-ccb4-469f-97d5-2795fe79bb29"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.26.4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "np.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6TaJ-A8NA52"
      },
      "source": [
        "## Load the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Fll-AsHCNY9d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import confugue\n",
        "import librosa\n",
        "import torch\n",
        "\n",
        "from ss_vq_vae.models.vqvae_oneshot import Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZ34SIFY6QrN",
        "outputId": "4c676fef-1330-45c8-deba-fed9121f82f9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (content_encoder): Sequential(\n",
              "    (0): Conv1d(1025, 1024, kernel_size=(4,), stride=(2,), padding=(2,))\n",
              "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv1d(1024, 1024, kernel_size=(4,), stride=(2,), padding=(2,))\n",
              "    (4): ResidualWrapper(\n",
              "      (module): Sequential(\n",
              "        (0): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (1): LeakyReLU(negative_slope=0.1)\n",
              "        (2): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
              "      )\n",
              "    )\n",
              "    (5): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (vq): VQEmbedding(\n",
              "    (embedding): Embedding(2048, 1024)\n",
              "  )\n",
              "  (style_encoder_1d): Sequential(\n",
              "    (0): Conv1d(1025, 1024, kernel_size=(4,), stride=(2,))\n",
              "    (1): ResidualWrapper(\n",
              "      (module): Sequential(\n",
              "        (0): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (1): LeakyReLU(negative_slope=0.1)\n",
              "        (2): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
              "      )\n",
              "    )\n",
              "    (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (style_encoder_rnn): GRU(1024, 1024, batch_first=True)\n",
              "  (style_encoder_0d): Sequential()\n",
              "  (decoder_modules): ModuleList(\n",
              "    (0): Sequential(\n",
              "      (0): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): LeakyReLU(negative_slope=0.1)\n",
              "      (2): ConvTranspose1d(2048, 1024, kernel_size=(1,), stride=(1,))\n",
              "      (3): ResidualWrapper(\n",
              "        (module): Sequential(\n",
              "          (0): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): LeakyReLU(negative_slope=0.1)\n",
              "          (2): RNNWrapper(\n",
              "            (rnn): GRU(1024, 1024, batch_first=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): LeakyReLU(negative_slope=0.1)\n",
              "      (6): ConvTranspose1d(1024, 1024, kernel_size=(4,), stride=(2,), padding=(2,), output_padding=(1,))\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): LeakyReLU(negative_slope=0.1)\n",
              "      (2): ConvTranspose1d(2048, 1024, kernel_size=(1,), stride=(1,))\n",
              "      (3): ResidualWrapper(\n",
              "        (module): Sequential(\n",
              "          (0): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): LeakyReLU(negative_slope=0.1)\n",
              "          (2): RNNWrapper(\n",
              "            (rnn): GRU(1024, 1024, batch_first=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): LeakyReLU(negative_slope=0.1)\n",
              "      (6): ConvTranspose1d(1024, 1024, kernel_size=(4,), stride=(2,), padding=(2,), output_padding=(1,))\n",
              "      (7): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (8): LeakyReLU(negative_slope=0.1)\n",
              "      (9): ConvTranspose1d(1024, 1025, kernel_size=(1,), stride=(1,))\n",
              "      (10): ResidualWrapper(\n",
              "        (module): Sequential(\n",
              "          (0): BatchNorm1d(1025, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): LeakyReLU(negative_slope=0.1)\n",
              "          (2): RNNWrapper(\n",
              "            (rnn): GRU(1025, 1025, batch_first=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (11): ReLU()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "cfg = confugue.Configuration.from_yaml_file(os.path.join(logdir, 'config.yaml'))\n",
        "exp = cfg.configure(Experiment, logdir=logdir, device='cpu')\n",
        "exp.model.load_state_dict(torch.load(os.path.join(logdir, 'model_state.pt'), map_location=exp.device))\n",
        "exp.model.train(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_Lt4SMAfOXBI"
      },
      "outputs": [],
      "source": [
        "INPUT_ROOT = 'https://adasp.telecom-paris.fr/rc-ext/demos_companion-pages/vqvae_examples/'\n",
        "INPUT_URLS = {\n",
        "    'Electric Guitar': INPUT_ROOT + 'real/content/UnicornRodeo_Maybe_UnicornRodeo_Maybe_Full_25_ElecGtr2CloseMic3.0148.mp3',\n",
        "    'Electric Organ': INPUT_ROOT + 'real/style/AllenStone_Naturally_Allen%20Stone_Naturally_Keys-Organ-Active%20DI.0253.mp3',\n",
        "    'Jazz Piano': INPUT_ROOT + 'real/style/MaurizioPagnuttiSextet_AllTheGinIsGone_MaurizioPagnuttiSextet_AllTheGinIsGone_Full_12_PianoMics1.08.mp3',\n",
        "    'Synth': INPUT_ROOT + 'real/content/Skelpolu_TogetherAlone_Skelpolu_TogetherAlone_Full_13_Synth.0190.mp3',\n",
        "    'Rhodes DI': INPUT_ROOT + 'real/content/Diesel13_ColourMeRed_Diesel13_ColourMeRed_Full_30_RhodesDI.0062.mp3',\n",
        "    'Acoustic Guitar Lead': INPUT_ROOT + 'real/style/NikolaStajicFtVlasisKostas_Nalim_Nikola%20Stajic%20ft.%20Vlasis%20Kostas_Nalim_Acoustic%20Guitar-Lead-Ela%20M%20251.0170.mp3',\n",
        "    'Bass Amp': INPUT_ROOT + 'real/content/HurrayForTheRiffRaff_LivingInTheCity_Hurray%20for%20the%20Riff%20Raff_Livin%20in%20the%20City_Bass-Amp-M82.0018.mp3',\n",
        "    'Bass Bip': INPUT_ROOT + 'real/style/RememberDecember_CUNextTime_RememberDecember_CUNextTime_Full_11_Bass_bip.041.mp3',\n",
        "    'SynthFX': INPUT_ROOT + 'real/content/MR0902_JamesElder_MR0902_JamesElder_Full_13_SynthFX1.163.mp3',\n",
        "    'Electric Guitar Close': INPUT_ROOT + 'real/style/Fergessen_TheWind_Fergessen_TheWind_Full_17_SlecGtr3a_Close.146.mp3',\n",
        "    'Rhodes NBATG': INPUT_ROOT + 'real/content/NickiBluhmAndTheGramblers_GoGoGo_NBATG%20-%20Rhodes%20-%20DI.098.mp3',\n",
        "    'Keys DI Grace': INPUT_ROOT + 'real/style/JessicaChildress_SlowDown_SD%20KEYS-DI-GRACE.147.mp3',\n",
        "    'Dulcimer': INPUT_ROOT + 'real/content/ButterflyEffect_PreachRightHere_ButterflyEffect_PreachRightHere_Full_16_Dulcimer2.076.mp3',\n",
        "    'Strings Section': INPUT_ROOT + 'real/style/AngeloBoltini_ThisTown_AngeloBoltini_ThisTown_Full_47_Strings_SectionMic_Vln2.0181.mp3',\n",
        "    'Mellotron': INPUT_ROOT + 'real/content/Triviul_Dorothy_Triviul_Dorothy_Full_07_Mellotron.120.mp3',\n",
        "    'Acoustic Guitar CU': INPUT_ROOT + 'real/style/UncleDad_WhoIAm_legend-strings_AC%20GUITAR-3-CU29-SHADOWHILL.R.0106.mp3',\n",
        "    'Fiddle': INPUT_ROOT + 'real/content/EndaReilly_CurAnLongAgSeol_EndaReilly_CurAnLongAgSeol_Full_10_Fiddle2.0163.mp3',\n",
        "    'Violins': INPUT_ROOT + 'real/style/ScottElliott_AeternumVale_ScottElliott_AeternumVale_Full_41_Violins.0138.mp3',\n",
        "    'Upright Bass': INPUT_ROOT + 'real/content/AbletonesBigBand_SongOfIndia_UPRIGHT%20BASS%20-%20ELA%20M%20260%20-%20Neve%2033102.136.mp3',\n",
        "    'Taiko': INPUT_ROOT + 'real/style/CarlosGonzalez_APlaceForUs_CarlosGonzalez_APlaceForUs_Full_21_Taiko.0115.mp3',\n",
        "    'Guitar 2': INPUT_ROOT + 'real/content/AllHandsLost_Ambitions_AllHandsLost_Ambitions_Full_Guitar%202.0292.mp3',\n",
        "    'Alto Sax': INPUT_ROOT + 'real/style/SunshineGarciaBand_ForIAmTheMoon_zip5-outro-uke-shaker_OUTRO%20ALTO-251E-SSL6000E.0290.mp3',\n",
        "    'Bass Close Mic': INPUT_ROOT + 'real/content/DonCamilloChoir_MarshMarigoldsSong_DonCamilloChoir_MarshMarigoldsSong_Full_08_BassCloseMic2.000.mp3',\n",
        "    'Electric Guitar Distorted': INPUT_ROOT + 'real/style/EnterTheHaggis_TwoBareHands_25.%20Jubilee%20Riots%20-%202%20Bar%20Hands_ELE%20Guitars-Ignater-M81.160.mp3',\n",
        "    'Bells': INPUT_ROOT + 'real/content/cryonicPAX_Melancholy_cryonicPAX_Melancholy_Full_10_Bells.0034.mp3',\n",
        "    'Bass Mic 647': INPUT_ROOT + 'real/style/KungFu_JoyRide_40.%20Kung%20Fu%20-%20Joy%20ride_Bass-Mic-647.0090.mp3',\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OexqCfZq1a68"
      },
      "source": [
        "### Run the model on your own audio (first 8 seconds)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 🎵 VQ-VAE Timbre Transfer Demo\n",
        "\n"
      ],
      "metadata": {
        "id": "kYdfQRe6rVis"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jCUYFJUF3m4o",
        "outputId": "8681a5b2-133d-4281-facb-fff46cd1c40b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://9d3a63598b49df6a5e.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://9d3a63598b49df6a5e.gradio.live\" width=\"100%\" height=\"1100\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gradio/processing_utils.py:753: UserWarning: Trying to convert audio automatically from float32 to 16-bit int format.\n",
            "  warnings.warn(warning.format(data.dtype))\n"
          ]
        }
      ],
      "source": [
        "\"\"\"## Gradio Interface for Custom Audio Upload\"\"\"\n",
        "\n",
        "import gradio as gr\n",
        "import requests\n",
        "import tempfile\n",
        "\n",
        "# Separate content and style options based on URL paths\n",
        "CONTENT_OPTIONS = [key for key in INPUT_URLS.keys() if any(word in INPUT_URLS[key] for word in ['content'])]\n",
        "STYLE_OPTIONS = [key for key in INPUT_URLS.keys() if any(word in INPUT_URLS[key] for word in ['style'])]\n",
        "\n",
        "# Add remaining items to both lists if they don't contain 'content' or 'style'\n",
        "for key in INPUT_URLS.keys():\n",
        "    if key not in CONTENT_OPTIONS and key not in STYLE_OPTIONS:\n",
        "        CONTENT_OPTIONS.append(key)\n",
        "        STYLE_OPTIONS.append(key)\n",
        "\n",
        "def load_audio_from_url(url, sr=None):\n",
        "    \"\"\"Load audio from URL by downloading to temporary file\"\"\"\n",
        "    response = requests.get(url)\n",
        "    with tempfile.NamedTemporaryFile(suffix='.mp3', delete=False) as tmp_file:\n",
        "        tmp_file.write(response.content)\n",
        "        tmp_file_path = tmp_file.name\n",
        "\n",
        "    audio, _ = librosa.load(tmp_file_path, sr=sr)\n",
        "    os.unlink(tmp_file_path)\n",
        "    return audio\n",
        "\n",
        "def preview_content_preset(preset_name):\n",
        "    \"\"\"Load and return audio for content preset preview\"\"\"\n",
        "    if preset_name and preset_name in INPUT_URLS:\n",
        "        try:\n",
        "            audio = load_audio_from_url(INPUT_URLS[preset_name], sr=exp.sr)\n",
        "            preview_duration = 5\n",
        "            max_samples = int(preview_duration * exp.sr)\n",
        "            if len(audio) > max_samples:\n",
        "                audio = audio[:max_samples]\n",
        "            return (exp.sr, audio)\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading content preset: {e}\")\n",
        "            return None\n",
        "    return None\n",
        "\n",
        "def preview_style_preset(preset_name):\n",
        "    \"\"\"Load and return audio for style preset preview\"\"\"\n",
        "    if preset_name and preset_name in INPUT_URLS:\n",
        "        try:\n",
        "            audio = load_audio_from_url(INPUT_URLS[preset_name], sr=exp.sr)\n",
        "            preview_duration = 5\n",
        "            max_samples = int(preview_duration * exp.sr)\n",
        "            if len(audio) > max_samples:\n",
        "                audio = audio[:max_samples]\n",
        "            return (exp.sr, audio)\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading style preset: {e}\")\n",
        "            return None\n",
        "    return None\n",
        "\n",
        "def process_timbre_transfer(content_file, content_preset, style_file, style_preset, max_duration=8):\n",
        "    \"\"\"Process timbre transfer with uploaded files or presets\"\"\"\n",
        "    try:\n",
        "        # Load content audio\n",
        "        if content_file is not None:\n",
        "            a_content, _ = librosa.load(content_file, sr=exp.sr)\n",
        "        elif content_preset and content_preset in INPUT_URLS:\n",
        "            a_content = load_audio_from_url(INPUT_URLS[content_preset], sr=exp.sr)\n",
        "        else:\n",
        "            return None, \"Please upload a content file or select a content preset\"\n",
        "\n",
        "        # Load style audio\n",
        "        if style_file is not None:\n",
        "            a_style, _ = librosa.load(style_file, sr=exp.sr)\n",
        "        elif style_preset and style_preset in INPUT_URLS:\n",
        "            a_style = load_audio_from_url(INPUT_URLS[style_preset], sr=exp.sr)\n",
        "        else:\n",
        "            return None, \"Please upload a style file or select a style preset\"\n",
        "\n",
        "        # Limit duration\n",
        "        max_samples = int(max_duration * exp.sr)\n",
        "        if len(a_content) > max_samples:\n",
        "            a_content = a_content[:max_samples]\n",
        "        if len(a_style) > max_samples:\n",
        "            a_style = a_style[:max_samples]\n",
        "\n",
        "        # Preprocess\n",
        "        s_content = torch.as_tensor(exp.preprocess(a_content), device=exp.device)[None, :]\n",
        "        s_style = torch.as_tensor(exp.preprocess(a_style), device=exp.device)[None, :]\n",
        "        l_content, l_style = (torch.as_tensor([x.shape[2]], device=exp.device) for x in [s_content, s_style])\n",
        "\n",
        "        # Run model\n",
        "        with torch.no_grad():\n",
        "            s_output = exp.model(input_c=s_content, input_s=s_style,\n",
        "                               length_c=l_content, length_s=l_style)\n",
        "\n",
        "        # Postprocess\n",
        "        a_output = exp.postprocess(s_output.cpu().numpy()[0])\n",
        "\n",
        "        return (exp.sr, a_output), \"Transfer completed successfully!\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return None, f\"Error: {str(e)}\"\n",
        "\n",
        "# Create Gradio interface\n",
        "with gr.Blocks(title=\"VQ-VAE Timbre Transfer\", theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"\"\"\n",
        "    # 🎵 VQ-VAE Timbre Transfer Demo\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            gr.Markdown(\"### 🎼 Content Audio\")\n",
        "            content_file = gr.Audio(label=\"Upload Content Audio\", type=\"filepath\")\n",
        "            content_preset = gr.Dropdown(\n",
        "                choices=[\"\"] + CONTENT_OPTIONS,\n",
        "                label=\"Or choose preset\",\n",
        "                value=\"\"\n",
        "            )\n",
        "            content_preview = gr.Audio(\n",
        "                label=\"🔊 Content Preview (5s)\",\n",
        "                interactive=False,\n",
        "                visible=False\n",
        "            )\n",
        "\n",
        "        with gr.Column():\n",
        "            gr.Markdown(\"### 🎨 Style Audio\")\n",
        "            style_file = gr.Audio(label=\"Upload Style Audio\", type=\"filepath\")\n",
        "            style_preset = gr.Dropdown(\n",
        "                choices=[\"\"] + STYLE_OPTIONS,\n",
        "                label=\"Or choose preset\",\n",
        "                value=\"Electric Guitar Close\"\n",
        "            )\n",
        "            style_preview = gr.Audio(\n",
        "                label=\"🔊 Style Preview (5s)\",\n",
        "                interactive=False,\n",
        "                visible=True\n",
        "            )\n",
        "\n",
        "    max_duration = gr.Slider(1, 15, value=8, step=1, label=\"Max Duration (seconds)\")\n",
        "    process_btn = gr.Button(\"🚀 Transfer Timbre\", variant=\"primary\", size=\"lg\")\n",
        "\n",
        "    with gr.Row():\n",
        "        output_audio = gr.Audio(label=\"🎵 Output Audio\", interactive=False)\n",
        "        status_msg = gr.Textbox(label=\"Status\", interactive=False, max_lines=3)\n",
        "\n",
        "    # Hide previews when user uploads files\n",
        "    content_file.change(\n",
        "        fn=lambda file: gr.update(visible=False) if file is not None else None,\n",
        "        inputs=[content_file],\n",
        "        outputs=[content_preview]\n",
        "    )\n",
        "\n",
        "    style_file.change(\n",
        "        fn=lambda file: gr.update(visible=False) if file is not None else None,\n",
        "        inputs=[style_file],\n",
        "        outputs=[style_preview]\n",
        "    )\n",
        "\n",
        "    # Show previews when presets are selected\n",
        "    content_preset.change(\n",
        "        fn=lambda preset, file: (\n",
        "            preview_content_preset(preset) if preset and file is None else None,\n",
        "            gr.update(visible=bool(preset and file is None))\n",
        "        ),\n",
        "        inputs=[content_preset, content_file],\n",
        "        outputs=[content_preview, content_preview]\n",
        "    )\n",
        "\n",
        "    style_preset.change(\n",
        "        fn=lambda preset, file: (\n",
        "            preview_style_preset(preset) if preset and file is None else None,\n",
        "            gr.update(visible=bool(preset and file is None))\n",
        "        ),\n",
        "        inputs=[style_preset, style_file],\n",
        "        outputs=[style_preview, style_preview]\n",
        "    )\n",
        "\n",
        "    # Load default style preview\n",
        "    demo.load(\n",
        "        fn=lambda: preview_style_preset(\"Electric Guitar Close\"),\n",
        "        outputs=[style_preview]\n",
        "    )\n",
        "\n",
        "    # Process button\n",
        "    process_btn.click(\n",
        "        fn=process_timbre_transfer,\n",
        "        inputs=[content_file, content_preset, style_file, style_preset, max_duration],\n",
        "        outputs=[output_audio, status_msg]\n",
        "    )\n",
        "\n",
        "    gr.Markdown(\"\"\"\n",
        "    ### 🔧 Troubleshooting\n",
        "    - **Poor transfer quality?** Try different instrument combinations or adjust max duration\n",
        "    - **Audio doesn't load?** Check internet connection or try different presets\n",
        "    - **Processing slow?** Reduce max duration or try shorter audio clips\n",
        "\n",
        "    ### 📖 Citation\n",
        "    Original work by Ondřej Cífka (InterDigital R&D and Télécom Paris, 2020).\n",
        "    Demo by Ali Dulaimi.\n",
        "    \"\"\")\n",
        "\n",
        "# Launch the interface\n",
        "demo.launch(share=True, debug=True, height=1100)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Troubleshooting\n",
        "\n",
        "**Common Issues**:\n",
        "- If you get NumPy version errors: Make sure to restart runtime after NumPy downgrade\n",
        "- If installation fails: Don't re-run installation cells after restart\n",
        "- If audio doesn't load: Check that URLs are accessible or try different presets\n",
        "- If transfer sounds poor: Try different instrument combinations or adjust max duration\n",
        "\n",
        "**Best Practices**:\n",
        "- Use audio clips that are clear and not too noisy\n",
        "- 8-second clips usually work best for quality vs. processing time\n",
        "- Experiment with different style/content combinations"
      ],
      "metadata": {
        "id": "Fzw-WfJmrgip"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "A4ukMlZdq3fO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "c-_FsWhVNMeH",
        "BQtNAd1hNG6R",
        "E6TaJ-A8NA52"
      ],
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}