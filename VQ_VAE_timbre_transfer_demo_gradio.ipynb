{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nL589kr4K9i8"
      },
      "source": [
        "# Timbre transfer demo\n",
        "\n",
        "Copyright 2020 InterDigital R&D and Télécom Paris.  \n",
        "Original Author: Ondřej Cífka\n",
        "Updates: Ali Dulaimi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-_FsWhVNMeH"
      },
      "source": [
        "## Install packages"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Local Setup Instructions\n",
        "\n",
        "**For Google Colab**: Simply run all cells in order.\n",
        "\n",
        "**For Local Environment**:\n",
        "1. Install requirements\n",
        "2. The pip uninstall/install steps are needed because:\n",
        "   - The model requires specific PyTorch versions for compatibility\n",
        "   - NumPy version conflicts can occur with DDSP dependencies\n",
        "   - These steps ensure clean installation of compatible versions\n",
        "\n",
        "**Important**: After running the NumPy downgrade cell, restart your kernel/runtime before proceeding."
      ],
      "metadata": {
        "id": "vrwVND3eoLGg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaY5aWDDC7al",
        "outputId": "678d5073-d8c7-49d1-e2a9-dfa705c52f7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ss-vq-vae'...\n",
            "remote: Enumerating objects: 432, done.\u001b[K\n",
            "remote: Counting objects: 100% (69/69), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 432 (delta 58), reused 54 (delta 54), pack-reused 363 (from 1)\u001b[K\n",
            "Receiving objects: 100% (432/432), 17.87 MiB | 15.49 MiB/s, done.\n",
            "Resolving deltas: 100% (198/198), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/cifkao/ss-vq-vae.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YP868eFmNfLi"
      },
      "outputs": [],
      "source": [
        "!pip uninstall torch torchvision torchaudio accelerate -y -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbnP2LiQSS2j",
        "outputId": "98895c5f-7422-4b2f-fa72-eed69ddc608e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.5/53.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.7/90.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.9/58.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.4/323.4 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33mWARNING: Ignoring version 3.5.0 of ddsp since it has invalid metadata:\n",
            "Requested ddsp from https://files.pythonhosted.org/packages/46/34/521a494c2096fb43ecbafa08b7ccd092b53984cd8ace47f788eb2085f1ec/ddsp-3.5.0-py2.py3-none-any.whl has invalid metadata: .* suffix can only be used with `==` or `!=` operators\n",
            "    protobuf (<=3.20.*)\n",
            "              ~~~~~~~^\n",
            "Please use pip<24.1 if you need to use this version.\u001b[0m\u001b[33m\n",
            "\u001b[0m  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.4/101.4 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.4/887.4 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m106.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.9/165.9 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ss-vq-vae (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for crepe (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.7.19 requires torchvision>=0.11, which is not installed.\n",
            "peft 0.16.0 requires accelerate>=0.21.0, which is not installed.\n",
            "timm 1.0.16 requires torchvision, which is not installed.\n",
            "torchdata 0.11.0 requires torch>=2, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install ./ss-vq-vae/src 'numba>0.57' ddsp -q"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "⚠️ **Important**: After restarting the runtime, **DO NOT re-run the installation cells above**. Running them again may cause dependency conflicts and put you in an installation loop. Continue from the \"Load the model\" section.\n"
      ],
      "metadata": {
        "id": "DSSc9Da9qJMA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "ztHhX9kq0GUu",
        "outputId": "f2fd61ed-a61a-4eab-8efd-80d746f84a38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 2.0.2\n",
            "Uninstalling numpy-2.0.2:\n",
            "  Would remove:\n",
            "    /usr/local/bin/f2py\n",
            "    /usr/local/bin/numpy-config\n",
            "    /usr/local/lib/python3.11/dist-packages/numpy-2.0.2.dist-info/*\n",
            "    /usr/local/lib/python3.11/dist-packages/numpy.libs/libgfortran-040039e1-0352e75f.so.5.0.0\n",
            "    /usr/local/lib/python3.11/dist-packages/numpy.libs/libquadmath-96973f99-934c22de.so.0.0.0\n",
            "    /usr/local/lib/python3.11/dist-packages/numpy.libs/libscipy_openblas64_-99b71e71.so\n",
            "    /usr/local/lib/python3.11/dist-packages/numpy/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled numpy-2.0.2\n",
            "Collecting numpy<2.0\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "peft 0.16.0 requires accelerate>=0.21.0, which is not installed.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "0d8ef47ac946472594ae1da4fc77e5f5"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip uninstall numpy\n",
        "!pip install \"numpy<2.0\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference with a pre-trained model\n",
        "\n",
        "### Model Architecture Overview\n",
        "\n",
        "This VQ-VAE (Vector Quantized Variational AutoEncoder) model performs timbre transfer through three main components:\n",
        "\n",
        "### Key Components:\n",
        "- **Content Encoder**: Extracts musical content (notes, rhythm) from the input audio while discarding timbre information\n",
        "- **Style Encoder (RNN)**: Captures the timbral characteristics and playing style from the style audio using recurrent neural networks\n",
        "- **Decoder Modules**: Reconstructs audio by combining the content representation with the style features, generating output with the target timbre\n",
        "\n",
        "### Why Some Combinations Work Better:\n",
        "- **Harmonic similarity**: Instruments with similar harmonic structures transfer more effectively\n",
        "- **Spectral compatibility**: Instruments with overlapping frequency ranges produce cleaner results\n",
        "- **Temporal characteristics**: Instruments with similar attack/decay patterns maintain better musical expression"
      ],
      "metadata": {
        "id": "rQQIAClspcz-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQtNAd1hNG6R"
      },
      "source": [
        "## Download the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wy5E_vcBdXDV"
      },
      "source": [
        "#### Make sure to restart the session to load the correct NumPy version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZMig9ftDDb0o"
      },
      "outputs": [],
      "source": [
        "logdir = 'ss-vq-vae/experiments/model'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9FSW1ty4SlA",
        "outputId": "03004361-8f47-49ba-ca21-a819a4b0bbb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-13 14:41:44--  https://adasp.telecom-paris.fr/rc-ext/demos_companion-pages/vqvae_examples/ssvqvae_model_state.pt\n",
            "Resolving adasp.telecom-paris.fr (adasp.telecom-paris.fr)... 137.194.22.227, 2a04:8ec0:0:a::89c2:16e3\n",
            "Connecting to adasp.telecom-paris.fr (adasp.telecom-paris.fr)|137.194.22.227|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 222788899 (212M)\n",
            "Saving to: ‘ss-vq-vae/experiments/model/model_state.pt’\n",
            "\n",
            "ss-vq-vae/experimen 100%[===================>] 212.47M  14.9MB/s    in 16s     \n",
            "\n",
            "2025-07-13 14:42:02 (13.1 MB/s) - ‘ss-vq-vae/experiments/model/model_state.pt’ saved [222788899/222788899]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://adasp.telecom-paris.fr/rc-ext/demos_companion-pages/vqvae_examples/ssvqvae_model_state.pt -O $logdir/model_state.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lTeCHImQ0bhS",
        "outputId": "1220382e-f13d-4f96-c184-ebdb880595fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.26.4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "np.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6TaJ-A8NA52"
      },
      "source": [
        "## Load the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Fll-AsHCNY9d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import confugue\n",
        "from ddsp.colab import colab_utils\n",
        "import librosa\n",
        "import torch\n",
        "\n",
        "from ss_vq_vae.models.vqvae_oneshot import Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZ34SIFY6QrN",
        "outputId": "1759baba-3942-4709-878d-7c26ca1640a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (content_encoder): Sequential(\n",
              "    (0): Conv1d(1025, 1024, kernel_size=(4,), stride=(2,), padding=(2,))\n",
              "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.1)\n",
              "    (3): Conv1d(1024, 1024, kernel_size=(4,), stride=(2,), padding=(2,))\n",
              "    (4): ResidualWrapper(\n",
              "      (module): Sequential(\n",
              "        (0): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (1): LeakyReLU(negative_slope=0.1)\n",
              "        (2): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
              "      )\n",
              "    )\n",
              "    (5): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (vq): VQEmbedding(\n",
              "    (embedding): Embedding(2048, 1024)\n",
              "  )\n",
              "  (style_encoder_1d): Sequential(\n",
              "    (0): Conv1d(1025, 1024, kernel_size=(4,), stride=(2,))\n",
              "    (1): ResidualWrapper(\n",
              "      (module): Sequential(\n",
              "        (0): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (1): LeakyReLU(negative_slope=0.1)\n",
              "        (2): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
              "      )\n",
              "    )\n",
              "    (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): LeakyReLU(negative_slope=0.1)\n",
              "  )\n",
              "  (style_encoder_rnn): GRU(1024, 1024, batch_first=True)\n",
              "  (style_encoder_0d): Sequential()\n",
              "  (decoder_modules): ModuleList(\n",
              "    (0): Sequential(\n",
              "      (0): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): LeakyReLU(negative_slope=0.1)\n",
              "      (2): ConvTranspose1d(2048, 1024, kernel_size=(1,), stride=(1,))\n",
              "      (3): ResidualWrapper(\n",
              "        (module): Sequential(\n",
              "          (0): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): LeakyReLU(negative_slope=0.1)\n",
              "          (2): RNNWrapper(\n",
              "            (rnn): GRU(1024, 1024, batch_first=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): LeakyReLU(negative_slope=0.1)\n",
              "      (6): ConvTranspose1d(1024, 1024, kernel_size=(4,), stride=(2,), padding=(2,), output_padding=(1,))\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): LeakyReLU(negative_slope=0.1)\n",
              "      (2): ConvTranspose1d(2048, 1024, kernel_size=(1,), stride=(1,))\n",
              "      (3): ResidualWrapper(\n",
              "        (module): Sequential(\n",
              "          (0): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): LeakyReLU(negative_slope=0.1)\n",
              "          (2): RNNWrapper(\n",
              "            (rnn): GRU(1024, 1024, batch_first=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): LeakyReLU(negative_slope=0.1)\n",
              "      (6): ConvTranspose1d(1024, 1024, kernel_size=(4,), stride=(2,), padding=(2,), output_padding=(1,))\n",
              "      (7): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (8): LeakyReLU(negative_slope=0.1)\n",
              "      (9): ConvTranspose1d(1024, 1025, kernel_size=(1,), stride=(1,))\n",
              "      (10): ResidualWrapper(\n",
              "        (module): Sequential(\n",
              "          (0): BatchNorm1d(1025, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (1): LeakyReLU(negative_slope=0.1)\n",
              "          (2): RNNWrapper(\n",
              "            (rnn): GRU(1025, 1025, batch_first=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (11): ReLU()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "cfg = confugue.Configuration.from_yaml_file(os.path.join(logdir, 'config.yaml'))\n",
        "exp = cfg.configure(Experiment, logdir=logdir, device='cpu')\n",
        "exp.model.load_state_dict(torch.load(os.path.join(logdir, 'model_state.pt'), map_location=exp.device))\n",
        "exp.model.train(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_Lt4SMAfOXBI"
      },
      "outputs": [],
      "source": [
        "INPUT_ROOT = 'https://adasp.telecom-paris.fr/rc-ext/demos_companion-pages/vqvae_examples/'\n",
        "INPUT_URLS = {\n",
        "    'Electric Guitar': INPUT_ROOT + 'real/content/UnicornRodeo_Maybe_UnicornRodeo_Maybe_Full_25_ElecGtr2CloseMic3.0148.mp3',\n",
        "    'Electric Organ': INPUT_ROOT + 'real/style/AllenStone_Naturally_Allen%20Stone_Naturally_Keys-Organ-Active%20DI.0253.mp3',\n",
        "    'Jazz Piano': INPUT_ROOT + 'real/style/MaurizioPagnuttiSextet_AllTheGinIsGone_MaurizioPagnuttiSextet_AllTheGinIsGone_Full_12_PianoMics1.08.mp3',\n",
        "    'Synth': INPUT_ROOT + 'real/content/Skelpolu_TogetherAlone_Skelpolu_TogetherAlone_Full_13_Synth.0190.mp3',\n",
        "    'Rhodes DI': INPUT_ROOT + 'real/content/Diesel13_ColourMeRed_Diesel13_ColourMeRed_Full_30_RhodesDI.0062.mp3',\n",
        "    'Acoustic Guitar Lead': INPUT_ROOT + 'real/style/NikolaStajicFtVlasisKostas_Nalim_Nikola%20Stajic%20ft.%20Vlasis%20Kostas_Nalim_Acoustic%20Guitar-Lead-Ela%20M%20251.0170.mp3',\n",
        "    'Bass Amp': INPUT_ROOT + 'real/content/HurrayForTheRiffRaff_LivingInTheCity_Hurray%20for%20the%20Riff%20Raff_Livin%20in%20the%20City_Bass-Amp-M82.0018.mp3',\n",
        "    'Bass Bip': INPUT_ROOT + 'real/style/RememberDecember_CUNextTime_RememberDecember_CUNextTime_Full_11_Bass_bip.041.mp3',\n",
        "    'SynthFX': INPUT_ROOT + 'real/content/MR0902_JamesElder_MR0902_JamesElder_Full_13_SynthFX1.163.mp3',\n",
        "    'Electric Guitar Close': INPUT_ROOT + 'real/style/Fergessen_TheWind_Fergessen_TheWind_Full_17_SlecGtr3a_Close.146.mp3',\n",
        "    'Rhodes NBATG': INPUT_ROOT + 'real/content/NickiBluhmAndTheGramblers_GoGoGo_NBATG%20-%20Rhodes%20-%20DI.098.mp3',\n",
        "    'Keys DI Grace': INPUT_ROOT + 'real/style/JessicaChildress_SlowDown_SD%20KEYS-DI-GRACE.147.mp3',\n",
        "    'Dulcimer': INPUT_ROOT + 'real/content/ButterflyEffect_PreachRightHere_ButterflyEffect_PreachRightHere_Full_16_Dulcimer2.076.mp3',\n",
        "    'Strings Section': INPUT_ROOT + 'real/style/AngeloBoltini_ThisTown_AngeloBoltini_ThisTown_Full_47_Strings_SectionMic_Vln2.0181.mp3',\n",
        "    'Mellotron': INPUT_ROOT + 'real/content/Triviul_Dorothy_Triviul_Dorothy_Full_07_Mellotron.120.mp3',\n",
        "    'Acoustic Guitar CU': INPUT_ROOT + 'real/style/UncleDad_WhoIAm_legend-strings_AC%20GUITAR-3-CU29-SHADOWHILL.R.0106.mp3',\n",
        "    'Fiddle': INPUT_ROOT + 'real/content/EndaReilly_CurAnLongAgSeol_EndaReilly_CurAnLongAgSeol_Full_10_Fiddle2.0163.mp3',\n",
        "    'Violins': INPUT_ROOT + 'real/style/ScottElliott_AeternumVale_ScottElliott_AeternumVale_Full_41_Violins.0138.mp3',\n",
        "    'Upright Bass': INPUT_ROOT + 'real/content/AbletonesBigBand_SongOfIndia_UPRIGHT%20BASS%20-%20ELA%20M%20260%20-%20Neve%2033102.136.mp3',\n",
        "    'Taiko': INPUT_ROOT + 'real/style/CarlosGonzalez_APlaceForUs_CarlosGonzalez_APlaceForUs_Full_21_Taiko.0115.mp3',\n",
        "    'Guitar 2': INPUT_ROOT + 'real/content/AllHandsLost_Ambitions_AllHandsLost_Ambitions_Full_Guitar%202.0292.mp3',\n",
        "    'Alto Sax': INPUT_ROOT + 'real/style/SunshineGarciaBand_ForIAmTheMoon_zip5-outro-uke-shaker_OUTRO%20ALTO-251E-SSL6000E.0290.mp3',\n",
        "    'Bass Close Mic': INPUT_ROOT + 'real/content/DonCamilloChoir_MarshMarigoldsSong_DonCamilloChoir_MarshMarigoldsSong_Full_08_BassCloseMic2.000.mp3',\n",
        "    'Electric Guitar Distorted': INPUT_ROOT + 'real/style/EnterTheHaggis_TwoBareHands_25.%20Jubilee%20Riots%20-%202%20Bar%20Hands_ELE%20Guitars-Ignater-M81.160.mp3',\n",
        "    'Bells': INPUT_ROOT + 'real/content/cryonicPAX_Melancholy_cryonicPAX_Melancholy_Full_10_Bells.0034.mp3',\n",
        "    'Bass Mic 647': INPUT_ROOT + 'real/style/KungFu_JoyRide_40.%20Kung%20Fu%20-%20Joy%20ride_Bass-Mic-647.0090.mp3',\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Cg9ITFZN122"
      },
      "source": [
        "## Choose or record inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "Ff7q62XD_DPB",
        "outputId": "0a560d75-16c0-4aae-9423-5ba4cf21c545"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-13 14:42:13--  https://adasp.telecom-paris.fr/rc-ext/demos_companion-pages/vqvae_examples/real/style/ScottElliott_AeternumVale_ScottElliott_AeternumVale_Full_41_Violins.0138.mp3\n",
            "Resolving adasp.telecom-paris.fr (adasp.telecom-paris.fr)... 137.194.22.227, 2a04:8ec0:0:a::89c2:16e3\n",
            "Connecting to adasp.telecom-paris.fr (adasp.telecom-paris.fr)|137.194.22.227|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 162004 (158K) [audio/mpeg]\n",
            "Saving to: ‘content_input.mp3’\n",
            "\n",
            "content_input.mp3   100%[===================>] 158.21K   312KB/s    in 0.5s    \n",
            "\n",
            "2025-07-13 14:42:15 (312 KB/s) - ‘content_input.mp3’ saved [162004/162004]\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div id=\"id_1\"> </div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@title Content input\n",
        "# source of these audio files is on https://adasp.telecom-paris.fr/rc/demos_companion-pages/cifka-ss-vq-vae/\n",
        "content_input = 'Violins'  #@param [\"Record\", \"Electric Guitar\", \"Electric Organ\", \"Jazz Piano\", \"Synth\", \"Rhodes DI\", \"Acoustic Guitar Lead\", \"Bass Amp\", \"Bass Bip\", \"SynthFX\", \"Electric Guitar Close\", \"Rhodes NBATG\", \"Keys DI Grace\", \"Dulcimer\", \"Strings Section\", \"Mellotron\", \"Acoustic Guitar CU\", \"Fiddle\", \"Violins\", \"Upright Bass\", \"Taiko\", \"Guitar 2\", \"Alto Sax\", \"Bass Close Mic\", \"Electric Guitar Distorted\", \"Bells\", \"Bass Mic 647\"]\n",
        "record_seconds = 8 #@param {type:\"number\"}\n",
        "\n",
        "if content_input == 'Record':\n",
        "    a_content = colab_utils.record(seconds=record_seconds, sample_rate=exp.sr, normalize_db=0.1)\n",
        "else:\n",
        "    !wget {INPUT_URLS[content_input]} -O content_input.mp3\n",
        "    a_content, _ = librosa.load('content_input.mp3', sr=exp.sr)\n",
        "colab_utils.play(a_content, sample_rate=exp.sr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "mnlaBLSI_X8G",
        "outputId": "35077f9d-b662-4d5d-d91a-99a7ec01c31d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-13 14:42:25--  https://adasp.telecom-paris.fr/rc-ext/demos_companion-pages/vqvae_examples/real/style/Fergessen_TheWind_Fergessen_TheWind_Full_17_SlecGtr3a_Close.146.mp3\n",
            "Resolving adasp.telecom-paris.fr (adasp.telecom-paris.fr)... 137.194.22.227, 2a04:8ec0:0:a::89c2:16e3\n",
            "Connecting to adasp.telecom-paris.fr (adasp.telecom-paris.fr)|137.194.22.227|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 162004 (158K) [audio/mpeg]\n",
            "Saving to: ‘style_input.mp3’\n",
            "\n",
            "style_input.mp3     100%[===================>] 158.21K   224KB/s    in 0.7s    \n",
            "\n",
            "2025-07-13 14:42:27 (224 KB/s) - ‘style_input.mp3’ saved [162004/162004]\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div id=\"id_2\"> </div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@title Style input\n",
        "style_input = 'Electric Guitar Close'  #@param [\"Record\", \"Electric Organ\", \"Jazz Piano\", \"Acoustic Guitar Lead\", \"Bass Bip\", \"Electric Guitar Close\", \"Keys DI Grace\", \"Strings Section\", \"Acoustic Guitar CU\", \"Violins\", \"Taiko\", \"Alto Sax\", \"Electric Guitar Distorted\", \"Bass Mic 647\"]\n",
        "record_seconds = 8 #@param {type:\"number\"}\n",
        "\n",
        "if style_input == 'Record':\n",
        "    a_style = colab_utils.record(seconds=record_seconds, sample_rate=exp.sr, normalize_db=0.1)\n",
        "else:\n",
        "    !wget {INPUT_URLS[style_input]} -O style_input.mp3\n",
        "    a_style, _ = librosa.load('style_input.mp3', sr=exp.sr)\n",
        "colab_utils.play(a_style, sample_rate=exp.sr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neqYSLlmOvh-"
      },
      "source": [
        "## Run the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "IRzrF8zADDTi",
        "outputId": "c7bdb868-3c67-492b-a36b-9ad9a88dda55"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div id=\"id_3\"> </div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "s_content = torch.as_tensor(exp.preprocess(a_content), device=exp.device)[None, :]\n",
        "s_style = torch.as_tensor(exp.preprocess(a_style), device=exp.device)[None, :]\n",
        "l_content, l_style = (torch.as_tensor([x.shape[2]], device=exp.device) for x in [s_content, s_style])\n",
        "with torch.no_grad():\n",
        "    s_output = exp.model(input_c=s_content, input_s=s_style,\n",
        "                         length_c=l_content, length_s=l_style)\n",
        "a_output = exp.postprocess(s_output.cpu().numpy()[0])\n",
        "colab_utils.play(a_output, sample_rate=16000 * 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OexqCfZq1a68"
      },
      "source": [
        "### Run the model on your own audio (first 8 seconds)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 🎵 VQ-VAE Timbre Transfer Demo\n",
        "\n"
      ],
      "metadata": {
        "id": "kYdfQRe6rVis"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jCUYFJUF3m4o",
        "outputId": "b434236e-0127-4214-90f0-92a5af57d08c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://3629c487d475f93c9f.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://3629c487d475f93c9f.gradio.live\" width=\"100%\" height=\"1000\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gradio/processing_utils.py:753: UserWarning: Trying to convert audio automatically from float32 to 16-bit int format.\n",
            "  warnings.warn(warning.format(data.dtype))\n"
          ]
        }
      ],
      "source": [
        "\"\"\"## Gradio Interface for Custom Audio Upload\"\"\"\n",
        "\n",
        "import gradio as gr\n",
        "import requests\n",
        "import tempfile\n",
        "\n",
        "# Separate content and style options based on URL paths\n",
        "# This categorizes presets by looking for 'content' or 'style' keywords in the file paths\n",
        "CONTENT_OPTIONS = [key for key in INPUT_URLS.keys() if any(word in INPUT_URLS[key] for word in ['content'])]\n",
        "STYLE_OPTIONS = [key for key in INPUT_URLS.keys() if any(word in INPUT_URLS[key] for word in ['style'])]\n",
        "\n",
        "# Add remaining items to both lists if they don't contain 'content' or 'style' in their paths\n",
        "# This ensures all presets are available in both dropdowns for flexibility\n",
        "for key in INPUT_URLS.keys():\n",
        "    if key not in CONTENT_OPTIONS and key not in STYLE_OPTIONS:\n",
        "        CONTENT_OPTIONS.append(key)\n",
        "        STYLE_OPTIONS.append(key)\n",
        "\n",
        "def load_audio_from_url(url, sr=None):\n",
        "    \"\"\"Load audio from URL by downloading to temporary file\"\"\"\n",
        "    response = requests.get(url)\n",
        "    # Create temporary file to store downloaded audio (deleted after use)\n",
        "    with tempfile.NamedTemporaryFile(suffix='.mp3', delete=False) as tmp_file:\n",
        "        tmp_file.write(response.content)\n",
        "        tmp_file_path = tmp_file.name\n",
        "\n",
        "    # Load audio using librosa and clean up temp file\n",
        "    audio, _ = librosa.load(tmp_file_path, sr=sr)\n",
        "    os.unlink(tmp_file_path)  # Delete temporary file\n",
        "    return audio\n",
        "\n",
        "def process_timbre_transfer(content_file, content_preset, style_file, style_preset, max_duration=8):\n",
        "    \"\"\"Process timbre transfer with uploaded files or presets\n",
        "\n",
        "    Priority: uploaded files override preset selections\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load content audio (musical notes/melody to preserve)\n",
        "        # Priority: uploaded file > preset selection\n",
        "        if content_file is not None:\n",
        "            a_content, _ = librosa.load(content_file, sr=exp.sr)\n",
        "        else:\n",
        "            if content_preset and content_preset in INPUT_URLS:\n",
        "                a_content = load_audio_from_url(INPUT_URLS[content_preset], sr=exp.sr)\n",
        "            else:\n",
        "                return None, \"Please upload a content file or select a content preset\"\n",
        "\n",
        "        # Load style audio (timbre/texture to apply)\n",
        "        # Same priority logic as content\n",
        "        if style_file is not None:\n",
        "            a_style, _ = librosa.load(style_file, sr=exp.sr)\n",
        "        else:\n",
        "            if style_preset and style_preset in INPUT_URLS:\n",
        "                a_style = load_audio_from_url(INPUT_URLS[style_preset], sr=exp.sr)\n",
        "            else:\n",
        "                return None, \"Please upload a style file or select a style preset\"\n",
        "\n",
        "        # Limit duration to prevent memory issues and long processing times\n",
        "        max_samples = int(max_duration * exp.sr)\n",
        "        if len(a_content) > max_samples:\n",
        "            a_content = a_content[:max_samples]  # Truncate to max duration\n",
        "        if len(a_style) > max_samples:\n",
        "            a_style = a_style[:max_samples]\n",
        "\n",
        "        # Preprocess: Convert audio to model input format (spectrograms)\n",
        "        s_content = torch.as_tensor(exp.preprocess(a_content), device=exp.device)[None, :]\n",
        "        s_style = torch.as_tensor(exp.preprocess(a_style), device=exp.device)[None, :]\n",
        "        # Create length tensors for variable-length input handling\n",
        "        l_content, l_style = (torch.as_tensor([x.shape[2]], device=exp.device) for x in [s_content, s_style])\n",
        "\n",
        "        # Run model: Extract content features, extract style features, then recombine\n",
        "        with torch.no_grad():  # Disable gradient computation for inference\n",
        "            s_output = exp.model(input_c=s_content, input_s=s_style,\n",
        "                               length_c=l_content, length_s=l_style)\n",
        "\n",
        "        # Postprocess: Convert model output back to audio waveform\n",
        "        a_output = exp.postprocess(s_output.cpu().numpy()[0])\n",
        "\n",
        "        # Return audio in format expected by Gradio: (sample_rate, audio_array)\n",
        "        return (exp.sr, a_output), \"Transfer completed successfully!\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return None, f\"Error: {str(e)}\"\n",
        "\n",
        "# Create Gradio interface with modern theme\n",
        "with gr.Blocks(title=\"VQ-VAE Timbre Transfer\", theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"\"\"\n",
        "    # 🎵 VQ-VAE Timbre Transfer Demo\n",
        "\n",
        "    Transfer the timbre (tone/texture) from one audio source to another while preserving the musical content.\n",
        "\n",
        "    **Content**: Musical notes/melody that will be preserved\n",
        "    **Style**: Instrument timbre/texture that will be applied\n",
        "    \"\"\")\n",
        "\n",
        "    # Two-column layout for content and style inputs\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            gr.Markdown(\"### 🎼 Content Audio\")\n",
        "            content_file = gr.Audio(label=\"Upload Content Audio\", type=\"filepath\")\n",
        "            content_preset = gr.Dropdown(\n",
        "                choices=[\"\"] + CONTENT_OPTIONS,  # Empty string allows no selection\n",
        "                label=\"Or choose preset\",\n",
        "                value=\"\"  # No default selection\n",
        "            )\n",
        "\n",
        "        with gr.Column():\n",
        "            gr.Markdown(\"### 🎨 Style Audio\")\n",
        "            style_file = gr.Audio(label=\"Upload Style Audio\", type=\"filepath\")\n",
        "            style_preset = gr.Dropdown(\n",
        "                choices=[\"\"] + STYLE_OPTIONS,\n",
        "                label=\"Or choose preset\",\n",
        "                value=\"Electric Guitar Close\"  # Default style selection\n",
        "            )\n",
        "\n",
        "    # Duration control to balance quality vs processing time\n",
        "    max_duration = gr.Slider(1, 15, value=8, step=1, label=\"Max Duration (seconds)\")\n",
        "\n",
        "    process_btn = gr.Button(\"🚀 Transfer Timbre\", variant=\"primary\", size=\"lg\")\n",
        "\n",
        "    # Output section\n",
        "    with gr.Row():\n",
        "        output_audio = gr.Audio(label=\"🎵 Output Audio\", interactive=False)\n",
        "        status_msg = gr.Textbox(label=\"Status\", interactive=False, max_lines=3)\n",
        "\n",
        "    # Connect button click to processing function\n",
        "    process_btn.click(\n",
        "        fn=process_timbre_transfer,\n",
        "        inputs=[content_file, content_preset, style_file, style_preset, max_duration],\n",
        "        outputs=[output_audio, status_msg]\n",
        "    )\n",
        "\n",
        "# Launch with public sharing enabled and debug mode for development\n",
        "demo.launch(share=True, debug=True, height=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Troubleshooting\n",
        "\n",
        "**Common Issues**:\n",
        "- If you get NumPy version errors: Make sure to restart runtime after NumPy downgrade\n",
        "- If installation fails: Don't re-run installation cells after restart\n",
        "- If audio doesn't load: Check that URLs are accessible or try different presets\n",
        "- If transfer sounds poor: Try different instrument combinations or adjust max duration\n",
        "\n",
        "**Best Practices**:\n",
        "- Use audio clips that are clear and not too noisy\n",
        "- 8-second clips usually work best for quality vs. processing time\n",
        "- Experiment with different style/content combinations"
      ],
      "metadata": {
        "id": "Fzw-WfJmrgip"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "A4ukMlZdq3fO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "c-_FsWhVNMeH",
        "BQtNAd1hNG6R",
        "E6TaJ-A8NA52"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}